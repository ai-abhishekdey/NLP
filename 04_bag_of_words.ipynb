{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773637f3",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "\n",
    "**Author: Abhishek Dey**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8877ab",
   "metadata": {},
   "source": [
    "* **Bag of words** is a classical technique of representing **text into numbers (vectors)**\n",
    "\n",
    "* It was first mentioned in 1950s but became popular in 2000s\n",
    "\n",
    "* Disadvantage: It ignores semantic nature of words and doesn't consider the meaning of the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8c24b",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c0b7c",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8263f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"I love NLP\", \" NLP is fun and NLP is coding\", \"I love NLP and Coding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6648622",
   "metadata": {},
   "source": [
    "### Bag of words using sklearn count-vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f8330",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "* Sklearn count-vectorizer by default ignores words shorter than 2 characters. By default it uses the following regex \n",
    "\n",
    "```\n",
    "\n",
    "token_pattern=r'(?u)\\b\\w\\w+\\b'\n",
    "\n",
    "```\n",
    "\n",
    "* To inclue words with one character like **I, a** use:\n",
    "\n",
    "```\n",
    "token_pattern=r\"(?u)\\b\\w+\\b\" \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "\n",
    "vectors = count_vec.fit_transform(data)\n",
    "\n",
    "vectors = vectors.toarray()\n",
    "\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a4efb",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db749a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = count_vec.get_feature_names_out()\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27768609",
   "metadata": {},
   "source": [
    "### Vocubalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ca377",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08094a",
   "metadata": {},
   "source": [
    "### Using pandas for better visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c219eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vectors,columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c4570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
